{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kmj-wZ5LCyJ1"
      },
      "outputs": [],
      "source": [
        "!pip install scispacy\n",
        "!pip install spacy\n",
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bc5cdr_md-0.4.0.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i5j5guJKCZ3G"
      },
      "outputs": [],
      "source": [
        "import scispacy\n",
        "import json\n",
        "import spacy\n",
        "from sklearn.utils import shuffle\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gc23tnVqCs2X"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN6BcYwHD35U"
      },
      "outputs": [],
      "source": [
        "%cd drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGeIuuKRUl8W"
      },
      "outputs": [],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3TlB5wmCZ3I"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-cnq7UbRCZ3J"
      },
      "outputs": [],
      "source": [
        "types = ('LOC', 'CORONAVIRUS', 'LIVESTOCK', 'WILDLIFE', 'EVOLUTION', 'PHYSICAL_SCIENCE',\n",
        "'SUBSTRATE', 'MATERIAL', 'IMMUNE_RESPONSE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fBMDq2lSCZ3K"
      },
      "outputs": [],
      "source": [
        "X = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u_UxUt98CZ3M"
      },
      "outputs": [],
      "source": [
        "with open('./SS-NER-prune.json') as file:\n",
        "    for line in file:\n",
        "        d = json.loads(line)\n",
        "        X.append(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BpQNHTPICZ3M"
      },
      "outputs": [],
      "source": [
        "test_X = X[:int(len(X)*(0.2))]\n",
        "train_X = X[int(len(X)*(0.2)):]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H0w7Yo1CZ3M"
      },
      "source": [
        "## Spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIfp0sjCCZ3M"
      },
      "source": [
        "### en_ner_bc5cdr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fob2fJVKS_-8"
      },
      "outputs": [],
      "source": [
        "from spacy.util import minibatch, compounding\n",
        "import random\n",
        "from spacy.training.example import Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6IxSEogBCZ3N"
      },
      "outputs": [],
      "source": [
        "bc5cdr = spacy.load(\"en_ner_bc5cdr_md\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jSnVcXR3CZ3S"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer', 'parser', 'ner']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bc5cdr.pipe_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3P29lpXvCZ3S"
      },
      "outputs": [],
      "source": [
        "ner = bc5cdr.get_pipe('ner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5YgT8N1hCZ3S"
      },
      "outputs": [],
      "source": [
        "for name in bc5cdr.pipe_names:\n",
        "    if name != \"ner\":\n",
        "        bc5cdr.disable_pipe(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dXGDOZahCZ3S"
      },
      "outputs": [],
      "source": [
        "for i in types:\n",
        "    ner.add_label(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3czf2jUiCZ3T"
      },
      "outputs": [],
      "source": [
        "optimizer = ner.create_optimizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "J8_oXjwICZ3X"
      },
      "outputs": [],
      "source": [
        "new_train = []\n",
        "for x in train_X[200:300]:\n",
        "    if 'body' in x.keys() and 'entities' in x.keys():\n",
        "        text = x['body']\n",
        "        tmp = []\n",
        "        for i in range(len(x['entities'])):\n",
        "            cur = x['entities'][i]\n",
        "            tmp.append((cur['start'], cur['end'], cur['type']))\n",
        "        new_train.append((text, {\"entities\": tmp}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Li_tOBGtCZ3T"
      },
      "outputs": [],
      "source": [
        "n_iter = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AVtAceKCZ3X"
      },
      "outputs": [],
      "source": [
        "for itn in range(n_iter):\n",
        "    random.shuffle(new_train)\n",
        "    losses = {}\n",
        "    batches = minibatch(new_train, size=compounding(4., 32., 1.001))\n",
        "    for batch in batches:\n",
        "        texts, annotations = zip(*batch)\n",
        "        example = []\n",
        "            # Update the model with iterating each text\n",
        "        for i in range(len(texts)):\n",
        "            if len(texts[i]) > 100000:\n",
        "              continue\n",
        "            doc = bc5cdr.make_doc(texts[i])\n",
        "            example.append(Example.from_dict(doc, annotations[i]))\n",
        "        # Update the model\n",
        "        bc5cdr.update(example, sgd=optimizer, drop=0.5, losses=losses)\n",
        "        # ner.update(texts, annotations, sgd=optimizer, drop=0.35,\n",
        "        #                 losses=losses)\n",
        "            # doc = bc5cdr.make_doc(texts)\n",
        "            # for a in annotations:\n",
        "            #     example.append(Example.from_dict(doc, a))\n",
        "                \n",
        "            # Updating the weights\n",
        "        # bc5cdr.update(example, sgd=optimizer, drop=0.35, losses=losses)\n",
        "    print('Losses', losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "o-FYuatWERnh"
      },
      "outputs": [],
      "source": [
        "bc5cdr.meta['name'] = 'model80'  # rename model\n",
        "bc5cdr.to_disk('./')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr8NzTw9TmXD"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAmXzCLLCZ3N"
      },
      "outputs": [],
      "source": [
        "from spacy.scorer import Scorer\n",
        "from spacy.tokens import Doc\n",
        "from spacy.training.example import Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BVTbZhQCZ3N"
      },
      "outputs": [],
      "source": [
        "def evaluate(ner_model, examples):\n",
        "    scorer = Scorer()\n",
        "    example = []\n",
        "    for input_, annot in examples:\n",
        "        pred = ner_model(input_)\n",
        "        temp = Example.from_dict(pred, dict.fromkeys(annot))\n",
        "        example.append(temp)\n",
        "    scores = scorer.score(example)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cnSIcoDCZ3N"
      },
      "outputs": [],
      "source": [
        "scorer = Scorer(bc5cdr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7euN_DtCZ3N"
      },
      "outputs": [],
      "source": [
        "new_test = []\n",
        "for t in test_X:\n",
        "    txt = t['body']\n",
        "    et = {}\n",
        "    lst = []\n",
        "    for e in t['entities']:\n",
        "        lst.append((e['start'],e['end'],e['type']))\n",
        "    et['entities'] = lst\n",
        "    example = Example.from_dict(bc5cdr.make_doc(txt), et)\n",
        "    new_test.append(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2bfXOP2CZ3O"
      },
      "outputs": [],
      "source": [
        "scores = scorer.score(new_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m86n0n8-EuRW"
      },
      "outputs": [],
      "source": [
        "evaluate(bc5cdr, new_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "doc = bc5cdr(test_X[0]['body'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "entss = doc.ents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GThA1nGDCZ3X"
      },
      "outputs": [],
      "source": [
        "pred_y = defaultdict(list)\n",
        "ground_y = defaultdict(list)\n",
        "i = 0\n",
        "for d in test_X:\n",
        "    if i % 100 == 0: print(i)\n",
        "    doc = bc5cdr(d['body'])\n",
        "    tmp = defaultdict(list)\n",
        "    for e in doc.ents:\n",
        "        tmp[e.label_].append(e.text)\n",
        "    for key, val in tmp.items():\n",
        "        pred_y[key].extend(val)\n",
        "    ground = defaultdict(list)\n",
        "    for e in d['entities']:\n",
        "        ground[e['type']].append(e['text'])\n",
        "    for key, val in ground.items():\n",
        "        ground_y[key].extend(val)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RwcbQY1UCZ3Y"
      },
      "outputs": [],
      "source": [
        "def f1(y_true, y_pred):\n",
        "    i = list((Counter(y_true) & Counter(y_pred)).elements())\n",
        "    # i = set(y_true).intersection(y_pred)\n",
        "    recall = len(i) / len(y_true)\n",
        "    precision = len(i) / len(y_pred)\n",
        "    if recall + precision == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 2 * (precision * recall) / (precision + recall)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "W_WTCVJkCZ3Y"
      },
      "outputs": [],
      "source": [
        "def avgf1(true_y, pred_y):\n",
        "    f_list = []\n",
        "    for t, p in zip(true_y, pred_y):\n",
        "        f_list.append(f1(t, p))\n",
        "    return sum(f_list)/len(f_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CORONAVIRUS 0.3685243168788647\n",
            "EVOLUTION 0.5431761478394596\n",
            "WILDLIFE 0.49609891431014996\n",
            "PHYSICAL_SCIENCE 0.7311053722422336\n",
            "LIVESTOCK 0.33202250434657105\n",
            "SUBSTRATE 0.4034442244471359\n",
            "LOC 0.33667715268349346\n",
            "IMMUNE_RESPONSE 0.6283439344864685\n",
            "MATERIAL 0.500207453644279\n",
            "over all f1 0.48217778009762846\n"
          ]
        }
      ],
      "source": [
        "total = 0\n",
        "for key, val in ground_y.items():\n",
        "    tmp = avgf1(val, pred_y[key])\n",
        "    total += tmp\n",
        "    print(key, tmp)\n",
        "print('over all f1', total/len(types))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "baseline.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8fab05a02078c9fe43114537b998a6c26642569b3564c13b79e781038c3930d8"
    },
    "kernelspec": {
      "display_name": "Python 3.7.10 64-bit ('test': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
