{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "8fab05a02078c9fe43114537b998a6c26642569b3564c13b79e781038c3930d8"
    },
    "kernelspec": {
      "display_name": "Python 3.7.10 64-bit ('test': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "baseline.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmj-wZ5LCyJ1"
      },
      "source": [
        "!pip install scispacy\n",
        "!pip install spacy\n",
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bc5cdr_md-0.4.0.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5j5guJKCZ3G"
      },
      "source": [
        "import scispacy\n",
        "import json\n",
        "import spacy\n",
        "from sklearn.utils import shuffle\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc23tnVqCs2X"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN6BcYwHD35U"
      },
      "source": [
        "%cd drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGeIuuKRUl8W"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3TlB5wmCZ3I"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cnq7UbRCZ3J"
      },
      "source": [
        "types = ('LOC', 'CORONAVIRUS', 'LIVESTOCK', 'WILDLIFE', 'EVOLUTION', 'PHYSICAL_SCIENCE',\n",
        "'SUBSTRATE', 'MATERIAL', 'IMMUNE_RESPONSE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBMDq2lSCZ3K"
      },
      "source": [
        "X = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_UxUt98CZ3M"
      },
      "source": [
        "with open('./SS-NER-prune.json') as file:\n",
        "    for line in file:\n",
        "        d = json.loads(line)\n",
        "        X.append(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpQNHTPICZ3M"
      },
      "source": [
        "test_X = X[:int(len(X)*(0.2))]\n",
        "train_X = X[int(len(X)*(0.4)):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H0w7Yo1CZ3M"
      },
      "source": [
        "## Spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIfp0sjCCZ3M"
      },
      "source": [
        "### en_ner_bc5cdr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fob2fJVKS_-8"
      },
      "source": [
        "from spacy.util import minibatch, compounding\n",
        "import random\n",
        "from spacy.training.example import Example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IxSEogBCZ3N"
      },
      "source": [
        "bc5cdr = spacy.load(\"en_ner_bc5cdr_md\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSnVcXR3CZ3S"
      },
      "source": [
        "bc5cdr.pipe_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P29lpXvCZ3S"
      },
      "source": [
        "ner = bc5cdr.get_pipe('ner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YgT8N1hCZ3S"
      },
      "source": [
        "for name in bc5cdr.pipe_names:\n",
        "    if name != \"ner\":\n",
        "        bc5cdr.disable_pipe(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXGDOZahCZ3S"
      },
      "source": [
        "for i in types:\n",
        "    ner.add_label(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3czf2jUiCZ3T"
      },
      "source": [
        "optimizer = ner.create_optimizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8_oXjwICZ3X"
      },
      "source": [
        "new_train = []\n",
        "for x in train_X:\n",
        "    if 'body' in x.keys() and 'entities' in x.keys():\n",
        "        text = x['body']\n",
        "        tmp = []\n",
        "        for i in range(len(x['entities'])):\n",
        "            cur = x['entities'][i]\n",
        "            tmp.append((cur['start'], cur['end'], cur['type']))\n",
        "        new_train.append((text, {\"entities\": tmp}))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li_tOBGtCZ3T"
      },
      "source": [
        "n_iter = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AVtAceKCZ3X"
      },
      "source": [
        "for itn in range(n_iter):\n",
        "    random.shuffle(new_train)\n",
        "    losses = {}\n",
        "    batches = minibatch(new_train, size=compounding(4., 32., 1.001))\n",
        "    for batch in batches:\n",
        "        texts, annotations = zip(*batch)\n",
        "        example = []\n",
        "            # Update the model with iterating each text\n",
        "        for i in range(len(texts)):\n",
        "            if len(texts[i]) > 100000:\n",
        "              continue\n",
        "            doc = bc5cdr.make_doc(texts[i])\n",
        "            example.append(Example.from_dict(doc, annotations[i]))\n",
        "        # Update the model\n",
        "        bc5cdr.update(example, sgd=optimizer, drop=0.5, losses=losses)\n",
        "        # ner.update(texts, annotations, sgd=optimizer, drop=0.35,\n",
        "        #                 losses=losses)\n",
        "            # doc = bc5cdr.make_doc(texts)\n",
        "            # for a in annotations:\n",
        "            #     example.append(Example.from_dict(doc, a))\n",
        "                \n",
        "            # Updating the weights\n",
        "        # bc5cdr.update(example, sgd=optimizer, drop=0.35, losses=losses)\n",
        "    print('Losses', losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-FYuatWERnh"
      },
      "source": [
        "bc5cdr.meta['name'] = 'model60'  # rename model\n",
        "bc5cdr.to_disk('./')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr8NzTw9TmXD"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAmXzCLLCZ3N"
      },
      "source": [
        "from spacy.scorer import Scorer\n",
        "from spacy.tokens import Doc\n",
        "from spacy.training.example import Example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BVTbZhQCZ3N"
      },
      "source": [
        "def evaluate(ner_model, examples):\n",
        "    scorer = Scorer()\n",
        "    example = []\n",
        "    for input_, annot in examples:\n",
        "        pred = ner_model(input_)\n",
        "        temp = Example.from_dict(pred, dict.fromkeys(annot))\n",
        "        example.append(temp)\n",
        "    scores = scorer.score(example)\n",
        "    return scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cnSIcoDCZ3N"
      },
      "source": [
        "scorer = Scorer(bc5cdr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7euN_DtCZ3N"
      },
      "source": [
        "new_test = []\n",
        "for t in test_X:\n",
        "    txt = t['body']\n",
        "    et = {}\n",
        "    lst = []\n",
        "    for e in t['entities']:\n",
        "        lst.append((e['start'],e['end'],e['type']))\n",
        "    et['entities'] = lst\n",
        "    example = Example.from_dict(bc5cdr.make_doc(txt), et)\n",
        "    new_test.append(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2bfXOP2CZ3O"
      },
      "source": [
        "scores = scorer.score(new_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m86n0n8-EuRW"
      },
      "source": [
        "evaluate(bc5cdr, new_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GThA1nGDCZ3X"
      },
      "source": [
        "pred_y = []\n",
        "true_y = []\n",
        "i = 0\n",
        "for d in test_X:\n",
        "    if i % 100 == 0: print(i)\n",
        "    doc = bc5cdr(d['body'])\n",
        "    tmp = []\n",
        "    for e in doc.ents:\n",
        "        tmp.append(e.text)\n",
        "    pred_y.append(tmp)\n",
        "    ground = []\n",
        "    for e in d['entities']:\n",
        "        ground.append(e['text'])\n",
        "    true_y.append(ground)\n",
        "    i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwcbQY1UCZ3Y"
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    i = list((Counter(y_true) & Counter(y_pred)).elements())\n",
        "    # i = set(y_true).intersection(y_pred)\n",
        "    print(len(i))\n",
        "    recall = len(i) / len(y_true)\n",
        "    precision = len(i) / len(y_pred)\n",
        "    print('recall', recall)\n",
        "    print('precision', precision)\n",
        "    if recall + precision == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 2 * (precision * recall) / (precision + recall)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_WTCVJkCZ3Y"
      },
      "source": [
        "def avgf1(true_y, pred_y):\n",
        "    f_list = []\n",
        "    for t, p in zip(true_y, pred_y):\n",
        "        f_list.append(f1(t, p))\n",
        "    return sum(f_list)/len(f_list)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}